{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Accuracy: 1.0\n",
      "[[False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "# Using SciKit-Learn, train a logistic regression model on the Iris dataset. \n",
    "# Use all four features. Define only 2 labels: `virginica` and `non-virginica`. \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Print the keys of the iris dataset\n",
    "print(iris.keys())\n",
    "\n",
    "# Print the feature names\n",
    "print(iris.feature_names)\n",
    "\n",
    "# the input are the four features of the iris dataset (sepal length, sepal width, petal length, petal width)\n",
    "X = iris.data\n",
    "\n",
    "# take just two labels from the iris dataset: virginica and non-virginica\n",
    "y = iris.target_names[iris.target] == 'virginica'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# test_size=0.3 means 30% of the data is used for testing\n",
    "# random_state=42 is used to seed the random number generator, so that the same random sequence is generated every time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_train_std = sc.transform(X_train)\n",
    "# X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "# C is the inverse of the regularization strength, in other words, \n",
    "# the smaller the value of C, the stronger the regularization\n",
    "# the regularization term is used to prevent overfitting by penalizing large coefficients\n",
    "# large coefficients can lead to overfitting, because the model will be too complex and will fit the training data too closely\n",
    "# C=1000.0 means that the regularization term is very weak\n",
    "# random_state=42 is used to seed the random number generator, so that the same random sequence is generated every time\n",
    "lr = LogisticRegression(C=1000.0, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Predict the probabilities\n",
    "y_pred_proba = lr.predict_proba(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Create a table of the actual and predicted labels with\n",
    "table = np.column_stack((y_test, y_pred))\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "* The accuracy of the model is 1.0, indicating that it correctly classified all instances in the test set.\n",
    "* The predicted labels match the actual labels perfectly, as shown by the output table where each row contains [True True] or [False False], meaning the predicted label matches the actual label for each instance.\n",
    "\n",
    "Even though the model performed perfectly on this dataset, it's essential to evaluate it on other metrics, especially in real-world scenarios where perfect accuracy is rare. Here are some common metrics and how they would apply:\n",
    "\n",
    "## Precision: \n",
    "Measures the proportion of true positive predictions among all positive predictions. High precision indicates that the model does not generate many false positives.\n",
    "## Recall: \n",
    "Measures the proportion of true positive predictions among all actual positives. High recall indicates that the model captures most of the positive instances.\n",
    "## F1 Score: \n",
    "The harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "\n",
    "Given the accuracy is 100%, the precision, recall, and F1 score would all be 1.0 for this model on this dataset.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
